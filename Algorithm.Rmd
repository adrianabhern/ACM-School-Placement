---
title: "ACM School Placement"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Install Packages

```{r install packages, echo = FALSE}
# install.packages("gmapsdistance")
# install.packages("readxl")
# install.packages("googleway")
# install.packages("dplyr")
# install.packages("tidyr")
# install.packages("dummies")
install.packages("data.table")
# Nick mentioned there may be a useful package that breaks down script timings 
```

# Load Packages

```{r load packages}
library(gmapsdistance)
library(readxl)
#library("googleway")
library(dplyr)
library(tidyr)
library(data.table)
library(dummies)
```

# Read Data

This is fake data that may or may not represent an actual corps.

```{r load spreadsheets, message=F}
#acm_df <- read_excel(path = "Input 1 - ACM Data.xls")
# For some reason there is an empty row at the end of acm_df in the .xls, so it's removed here:
#acm_df <- acm_df[-nrow(acm_df),]

acm_df <- read.csv(file = "Input 1 - ACM Data.csv")
acm_commutes <- read_excel(path = "Input 2 - ACM Commutes.xlsx")
school_df <- read_excel(path = "Input 3 - School Data.xls")

# Add id columns
acm_df$id <- 1:nrow(acm_df)
acm_commutes$id <- 1:nrow(acm_commutes)
school_df$id <- 1:nrow(school_df)
```


# Generate Fake Data

```{r}
# Used for Birthdates
fake_dates <- function(N, st="1991/01/01", et="1996/12/31") {
     st <- as.POSIXct(as.Date(st))
     et <- as.POSIXct(as.Date(et))
     dt <- as.numeric(difftime(et,st,unit="secs"))
     ev <- runif(N, 0, dt)
     rt <- st + ev 
     trunc(rt, units = "days")}

generate_fake_df <- function(num_rows, school_df){
  fake_df <- data.frame(
    First.Name = rep('', num_rows),
      
    Last.Name = rep('', num_rows),
      
    Attnd.CY.School = sample( c('I did not attend a City Year school', school_df$`School Name`), num_rows, replace=TRUE, prob=c(0.95, rep(0.01, length(school_df$`School Name`)))),
    
    Language.Other.English =  sample( c('Yes', 'No'), num_rows, replace=TRUE, prob=c(0.2, 0.8) ),
                                    
    Language.Ability = sample( c('Spanish', 
                                 'French', 
                                 'Arabic',
                                 'Urdu',
                                 'Nepali',
                                 'Swahili',
                                 'Chinese (Mandarin)',
                                 'Chinese (Cantonese)',
                                 'Polish',
                                 'Other'), 
                               num_rows, replace=TRUE, prob=c(0.15, 0.05, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02,  0.02, 0.02) ),
  
    Tutoring.Experience = sample( c('Yes', 'No'), num_rows, replace=TRUE, prob=c(0.7, 0.3) ),
  
    Tutoring.Experience.Months = sample(1:12, num_rows, replace = TRUE, prob = 12:1),
    
    Tutoring.Experience.Grades = sample( c('Elementary School',
                                           'Elementary School, Middle School',
                                           'Middle School',
                                           'Middle School, High School',
                                           'High School',
                                           'Elementary School, High School',
                                           'Elementary School, Middle School, High School'), 
                                         num_rows, replace=TRUE, prob=c(0.15, 0.15, 0.15, 0.15, 0.15, 0.05, 0.1) ),
    
    Teaching.Credential = sample( c('Yes', 'No'), num_rows, replace=TRUE, prob=c(0.1, 0.9) ),
      
    Tutoring.Preference = sample( c('ELA', 
                                    'Math',
                                    'Either/No Preference'), num_rows, replace=TRUE, prob=c(0.4, 0.4, 0.2) ),
    
    Grade.Lvl.Preference = sample( c('Elementary School',
                                       'Elementary School, Middle School',
                                       'Middle School',
                                       'Middle School, High School',
                                       'High School',
                                       'Elementary School, High School',
                                       'Elementary School, Middle School, High School'), num_rows, replace=TRUE, prob=c(0.16, 0.16, 0.16, 0.16, 0.16, 0.01, 0.2) ),
      
    Math.Confidence = sample( c('Pre-algebra or lower', 
                                'Algebra I', 
                                'Algebra II', 
                                'Calculus or higher'), num_rows, replace=TRUE, prob=c(0.25, 0.25, 0.25, 0.25) ),
  
    Travel.Method = sample( c('Driving', 'Public Transit', 'Biking', 'Walking'), num_rows, replace=TRUE, prob=c(0.3, 0.6, 0.07, 0.03) ),
      
    Gender = sample( c('Female', 
                       'Male', 
                       'Transgender Male', 
                       'Transgender Female', 
                       'Gender Nonconforming (GNC)'), num_rows, replace=TRUE, prob=c(0.5, 0.3, 0.05, 0.05, 0.1) ),
      
    Birth.Date = fake_dates(num_rows),
    
    Race.Ethnicity = sample( c('African American/Black', 
                               'American Indian/Alaskan Native', 
                               'Asian', 
                               'Hispanic/Latino',
                               'Middle Eastern',
                               'Native Hawaiian or Pacific Islander',
                               'White/Caucasian',
                               'African American/Black, Hispanic/Latino', 
                               'Hispanic/Latino, White/Caucasian',
                               'Middle Eastern, White/Caucasian',
                               'African American/Black, White/Caucasian'), 
                             num_rows, replace=TRUE, prob=c(0.3, 0.03, 0.05, 0.13, 0.03, 0.03, 0.38, 0.05, 0.01, 0.01, 0.01) ),
    
    Educational.Attainment = sample( c('High School/GED', 
                                       'Some College',
                                       "Associate's Degree",
                                       "Bachelor's Degree",
                                       "Master's Desgree"),
                                     num_rows,   replace=TRUE, prob=c(0.2, 0.2, 0.15, 0.4, 0.05) ),
    
    Know.Living =  sample( c('Yes', 'No'), num_rows, replace=TRUE, prob=c(0.5, 0.5) ),
    
    Address.Line.1 = rep('', num_rows),
      
    Address.Line.2 = rep('', num_rows),
      
    City = rep('', num_rows),
      
    State =  rep('', num_rows),
      
    Postal.Code = rep('', num_rows),
    
    Roomates = sample( c('Yes', 'No'), num_rows, replace=TRUE, prob=c(0.5, 0.5) ),
    
    Roommate.Names = rep('none', num_rows)
  )
  
  fake_df$Language.Ability[fake_df$Language.Other.English == 'No'] <- NA
  fake_df$Tutoring.Experience.Months[fake_df$Tutoring.Experience == 'No'] <- NA
  fake_df$Tutoring.Experience.Grades[fake_df$Tutoring.Experience == 'No'] <- NA
  fake_df$Teaching.Credential[fake_df$Tutoring.Experience == 'No'] <- NA
  fake_df$Roommate.Names[fake_df$Roomates == 'No'] <- NA
  return(fake_df)
}
  
acm_df_fake <- generate_fake_df(247, school_df)
acm_df_fake
# write.table(acm_df_fake, file = "Input 1 - ACM Data.csv", sep=",", row.names=FALSE)
```

# Encode Variables & Clean Up Input Dataframes

Before being able to calculate a score, we'll need to encode all of our variables numerically.  For categorical variables, we can create a dummy variable for all except one of the categories (this is because the last category can be inferred).

```{r Encoding Variables}
# Encoding ACM variables with some help from `dummies` packages. The final select statement removes the then unnecessary variables. 
encode_vars <- function(df){
  # Ran into some trouble with the dpylr %>% pipeline.  Was causing strange names from using `dummies`. 
  acm_enc <- cbind(df, dummy(df$Education, sep="_education_"))
  acm_enc <- cbind(acm_enc, dummy(acm_enc$`Tutoring Experience`, sep="_tut exp_"))
  acm_enc <- cbind(acm_enc, dummy(acm_enc$`Tutoring Preference (Math, ELA, or No Pref)`, sep="_tut pref_")) # will possibly be removed
  acm_enc <- cbind(acm_enc, dummy(acm_enc$`Grade Level Preference (3-5, 6-8, or 9)`, sep="_gl pref_"))
  acm_enc$`Math Ability` <- ifelse(acm_enc$`Math Ability`=="Pre-Algebra or lower" | acm_enc$`Math Ability`=="Algebra I", 0, 1)
  acm_enc <- cbind(acm_enc, dummy(acm_enc$Languages, sep="_"))
  
  # Remove the excess columns we won't use for scoring
  acm_enc <- select(acm_enc, -(`First Name`:`Method of Commute`), -(`Tutoring Preference (Math, ELA, or No Pref)`:Languages), -(`Tutoring Experience`:`Manual Zone Placement`), -(acm_df_education_College), -`acm_df_tut exp_ `, -`acm_df_tut pref_No Preference`, -`acm_df_ `)
  
  # Return
  acm_enc
}

# School configuration data frame. I think we could probably reduce the school configuration file to just the following elements: school name, team size, address, and local ethnic demographics.  From those data npoints alone and the corps demographic data, we should be able to calculate everything else.  

# This function calculates some import counts which I'm going to use a lot when trying to figure out the expected number of ACMs per team per metric.  This function will just be used internally by the school_config function.
corps_demographic_targets <- function(school_df, acm_df){
  N <- nrow(acm_df)
  S <- nrow(school_df)
  school_counts <- group_by(school_df, `School Type`) %>% summarise(count=n())
  dense_hispanic <- nrow(school_df[school_df$`% Hispanic` > 10, ])
  distros <- list()
  distros$education <- group_by(acm_df, Education) %>% 
    summarise(count=n()) %>% 
    mutate(ratio = count/N)
  distros$gl_pref <- group_by(acm_df, `Grade Level Preference (3-5, 6-8, or 9)`) %>% 
    summarise(acm_count=n()) %>% 
    left_join(., school_counts, by = c("Grade Level Preference (3-5, 6-8, or 9)" = "School Type")) %>%
    mutate(exp_acms = acm_count/count)
  distros$tut_exp <- group_by(acm_df, `Tutoring Experience`) %>%
    summarise(acm_count=n())  %>% 
    left_join(., school_counts, by = c("Tutoring Experience" = "School Type")) %>%
    mutate(exp_acms = acm_count/count)
  distros$lang <- group_by(acm_df, Languages) %>% 
    summarise(count=n()) %>% 
    mutate(ratio = count/N)
  distros
}

# I derived this function mildly arbitrarily. The logic is that we probably want at least one spanish speaker at a school, but there are then diminishing returns.  It scales so that for a school that 100% hispanic, we would aim to have 5 spanish speakers on the team.  A team thats 50% hispanic will aim to have 4. The main problem with this approach is that we may create too many spots for spanish speakers, or have not have enough spanish speakers for the intended spots.  
spanishNeed <- function(x) {
  1.5772*log(x) - 2.1205
}

# Directly calculates the expected number of ACMs per team for each of the markers.
# My methodology is to aim for a uniform distribution when it makes sense.  So, for example, if we have 10 elementary schools and 30 ACMs who prefer ES.  Then I will try to evenly distribute by sending 3 of these ACMs to each ES.  Tutoring experience is that same procedure. For education, we're simply trying to spread out the high school and some college folks, since they'll typically be our least common types.  We don't need to set a target for college grads, since they essentially fill in the rest of the placement. Lastly is language.  I want some method of prioritizing spanish speakers so that schools with lots of spanish speakers get more spanish speaking ACMs.  For right now I'm implamenting a fairly simple method which don't consider the total number of 
school_config <- function(school_df, acm_df){
  # Precalculate some helpful counts
  corps_demos <- corps_demographic_targets(school_df, acm_df)
  # Unravel list into some variables.  Mostly so that the code is a little cleaner later.
  education <- corps_demos$education
  gl_pref <- corps_demos$gl_pref
  tut_exp <- corps_demos$tut_exp
  
  school.data <- select(school_df, `School_ID`, `Team Size`, `School Type`, `% Caucasian`:`% N/A`) %>%
    rename(size = `Team Size`,
           span = `School Type`) %>%
    mutate(Ed_SomeCollege = education[education$Education %in% "Some College",]$ratio * size,
           Ed_HighSchool = ifelse(span=="HS", 0, corps_demos$education[education$Education %in% "High School",]$ratio * size),
           SpanPref_ES = ifelse(span=="ES", pmin(size, gl_pref[gl_pref$`Grade Level Preference (3-5, 6-8, or 9)` %in% "ES",]$exp_acms), 0),
           SpanPref_MS = ifelse(span=="MS", pmin(.$size, gl_pref[gl_pref$`Grade Level Preference (3-5, 6-8, or 9)` %in% "MS",]$exp_acms), 0),
           SpanPref_HS = ifelse(span=="HS", pmin(.$size, gl_pref[gl_pref$`Grade Level Preference (3-5, 6-8, or 9)` %in% "HS",]$exp_acms), 0),
           TutExp_ES = ifelse(span=="ES", pmin(size, tut_exp[tut_exp$`Tutoring Experience` %in% "ES",]$exp_acms), 0),
           TutExp_MS = ifelse(span=="MS", pmin(size, tut_exp[tut_exp$`Tutoring Experience` %in% "MS",]$exp_acms), 0),
           TutExp_HS = ifelse(span=="HS", pmin(size, tut_exp[tut_exp$`Tutoring Experience` %in% "HS",]$exp_acms), 0),
           SpanishNeed = pmax(spanishNeed(`% Hispanic`), 1)) # This sets a minimum of 1 spanish speaker per team.  This might make sense in LA, but not other places.
}

acm_enc <- encode_vars(acm_df)
school_targets <- school_config(school_df, acm_df)

```



 
# Calculate Commutes

To calculate commute times, we essentially send many requests to Google Maps through an API (Applciation Program Interface). To get access to the API we need a key. Visit the [Google Distance Matrix API](https://developers.google.com/maps/documentation/distance-matrix/) page. Click "GET A KEY" in the upper right corner. Save the key privately. This key identifies you to Google.

Many organizations provide access to their data through an API. Many times this service is free, but some organizations charge for this service because of processing costs and the benefits that this access enables. Google will allow you to calculate 2,500 travel times for free in one day. After that, you will need to pay $0.50 for each 1,000 requests, or wait a day to calculate 2,500 more.

The key I included in this script is a free-use key, so it will be limited to 2,500 results per day. However, I did opt to enable pay-as-you-go on my personal key (not shared here). In CYCHI, this expense will hopefully be covered under our Impact Team budget.

```{r commute times}
# Prior to this step, you may need to ensure that "Address Line 1" 
# does not include any apartment/suite/room info.

# Note that for public tansit, google does not count 
# the time spent waiting for the bus/train. For example, 
# let's say I get off work at 5pm and a bus comes at 5:15pm. 
# I ride the bus 45 minutes to get home. My commute is more 
# accurately described as 60 minutes, but this function would 
# still return 45 minutes.

calc_commutes = function(){

  # This line combines address data into one text string:
  acm_df$"Full Address" = paste(acm_df$"Address Line 1", acm_df$"City", acm_df$"State", acm_df$"Postal Code")
  
  # Replace spaces with "+" and remove commas (requests to google maps API cannot include spaces)
  acm_df$"Full Address" = gsub(" ", "+", acm_df$"Full Address")
  school_df$"Address" = gsub(" ", "+", school_df$"Address")
  school_df$"Address" = gsub(",", "", school_df$"Address")
  
  # Input your own API Key here
  set.api.key("AIzaSyDFlU9RkmJBJdw0YGMswYECXQeZeKxFmuc")
  
  # Create an empty dataframe that we will fill with commute times
  acm_commutes <- data.frame()
  
  # Create a for loop that will read through each row of ACM data, feed it into the main function of our gmapsdistance package, and build a new data frame of commute info.
  for (acm_id in acm_df[1:2,]$id){
    
    # select just one row from acm_df, and assign it to a new object, acm_row
    acm_row <- subset(acm_df, id == acm_id)
    
    # feed that ACM's address and mode into the function 'gmapsdistance'. This will return a new object that is a single row of ACM commute times to each school. That row is assigned to a new object, 'commute'
    commute = gmapsdistance(origin = acm_row$"Full Address", destination = school_df[1:2,]$"Address", mode = acm_row$"Method of Commute", combinations = "all", shape = "wide")
    
    # create an 'id' column in our new 'commute' row that is the same as acm_id. We will use this to join our data frames.
    commute$Time[["id"]] = acm_id
    
    # as the for-loop runs, progressively add each single row of commute data into a new data frame called acm_commutes. As this for-loop runs, this dataframe grows to include all ACM's.
    acm_commutes <- rbind(acm_commutes, commute$Time)
  }
  
  acm_commutes

  }

```

# Initial Team Placements
  
Generate a list of team id numbers for each team that is the length of each team's size. Combine these lists into one long list of initial team assignments.
  
```{r}  
# Assumption: the number of ACMs in acm_df is exactly the same as the number of team slots

initial_placement <- function(){
  # first create an empty list
  team_placements = list()
  
  # use a for-loop to read each team size
  for (x in 1:nrow(school_df)){
    team_slots = list(
      # create a list that repeats each school 'id' for the size of each team
      rep(x, 
          subset(school_df$"Team Size", school_df$"id" == x)
          )
      )
    team_placements <- c(team_placements, team_slots)
  }
  
  team_placements <- data.frame(placement=unlist(team_placements))
  
  # Randomize Starting Place
  data.frame(placement=team_placements[sample(nrow(team_placements), replace=F), ], 
             id= 1:nrow(team_placements))
}


team_placements_df <- initial_placement()

```

### Calculate score

This is the function that calculates the quality of each placement.

One thing we should try to avoid is validating all of our placement every time we swap.  Instead we should try to implament our hard constraints through the cost function.  For example, if we weight the high school grad target really high, thus imposing a large penalty on any placement where a high school graduate is placed at a high school

```{r}
# Chris
## Chris: We want the following characteristics to be represented evenly across teams. We calculate ratios  for the # entire corps, and later calculate how well each team matches these ratios.

# calc percent prevalence each gender category in entire corps, calc difference between those numbers and that found within school teams

# Gen random placements
acm_df$sch_id <- sample(1:26, nrow(acm_df), replace = TRUE)
  # Note: move this inside the loop of assignments

# Create data.frame with each potential combination of gender and school
gender_frame <- 
  expand.grid(sch_id = 1:26, Gender = levels(acm_df$Gender))
  # Note--need to replace sch_id with the appropriate school id values based off of the data

# Create tibbl representing percentages of each gender category across entire corps
gender_g <- group_by(acm_df, Gender) %>% summarize(pct_g = n()/nrow(acm_df))

# Merge them by "gender"
gender_frame_g <-
  merge(x = gender_frame,
        y = gender_g,
        by = "Gender",
        all.x = TRUE)


# Represent percentage of each gender category within each team
gender_gs <- 
  acm_df %>%
  group_by(sch_id, Gender) %>%
  dplyr::summarize(n_gs = n()) %>%
  group_by(sch_id) %>%
  dplyr::mutate(pct_gs = n_gs/sum(n_gs))

# Calculate absolute value of difference between gender percentages at each team and across the corps
gender_frame_gs <-
  merge(x = gender_frame_g,
        y = gender_gs,
        by = c("sch_id", "Gender"),
        all.x = TRUE) %>%
  within({
    diff_gs <- pct_g - ifelse(is.na(pct_gs), 0, pct_gs)
    abs_diff_gs <- abs(diff_gs)
  }) %>%
  summarise(mean_gend_diff = mean(abs_diff_gs))

  # age - group by school, get age variance, 
  age_var <- 
    group_by(acm_df, sch_id) %>%
    summarize(age_var = var(age)) %>%
    ungroup() %>%
    summarize(avg_age_var = mean(age_var))

  # To prevent 
  
  # ethnicity

  # attend local school, CY or local

  # roommates? not necessary?

# Alex
  # educational attainment (potentially different goals for HS/ES)
  # tutoring experience (look at notes from survey)
  # tutoring preference
  # grade level preference
  # language speaking
```

```{r}
PickTime <- function(myid, myplace){subset(acm_commutes,
                                              subset = id == myid,
                                              select = myplace+1)}




## Characteristics that we don't want to be even across all schools
# edu.attainment.hs.ideal <- 
# edu.attainment.es.ideal <- 
# spanish
  
# Commute times in long format will be easier to index and subset
acm_commutes_long <-
  select(acm_commutes, -or) %>%
  gather(dest, dist, -id) %>%
  mutate(id_dest = paste(id, dest, sep = "_"))

calculate_score = function(acm_df, team_placements_df) {
  
  ## Convert the team_placement list into a dataframe with an 'id' column 
  # team_placements_df <- data.frame(id = 1:length(team_placements),
  #                                 Team.Placement = team_placements)
  
  ## New! Convert the team_placement list into a dataframe with an 'id' column 
  # team_placements_df <- data.frame(id = 1:length(team_placements),
  #                                  Team.Placement = team_placements,
  #                                  dest = colnames(acm_commutes)[team_placements + 1]) %>%
  #   within(id_dest <- paste(id, dest, sep = "_"))
  
  
  # Merge team_placements_df with acm_df on the 'id' column we just created
  acm_df_with_placements <- merge(acm_df, team_placements_df, by = "id", all.x = TRUE)
  
  # Merge acm_df_with_placements with school_df to pull in school characteristics
  acm_df_with_placements <- merge(acm_df_with_placements, school_df, by.x = "placement", by.y = "id", all.x = TRUE)
  
  #Placement.Scores <-
  #  group_by(acm_df_with_placements, Team.Placement) %>%
  #  summarize(gender.ratio = sum(Gender == "Male")/sum(Gender == "Female"),
  #            age.var = var(Age)) %>%
  #  mutate(gender.ratio.dev = abs(gender.ratio - gender.ratio.ideal)) %>%
  #  ungroup() %>%
  ## 3 is some arbitrary score weight
  #  summarize(gender.ratio.score = mean(gender.ratio.dev)*3,
  #            avg.age.var = -mean(age.var))
  ## Also, negative scores are better, and the "-" in front of mean age variance means that
  ## higher average variance of team ages gets relatively more favorable scores.
  
  ## NSM's new method for calling commute times
  # system.time({
  #   filter(acm_commutes_long, id_dest %in% team_placements_df$id_dest) %>%
  #     summarize(sum(dist))
  # })
 
  ## NSM: even faster way to do the same thing, with the data.table package
  team_placements_df$dest = colnames(acm_commutes)[team_placements_df$placement + 1]
  
  team_placements_df <- within(team_placements_df, id_dest <- paste(id, dest, sep = "_"))
  
  dt_commutes <- data.table(acm_commutes_long)
  
  dt_commutes[id_dest %in% team_placements_df$id_dest,  sum(dist)]
  
  #browser()
  
  ## Old commute calc method references functions defined just before 'calculate_score'
  # acm_df_with_placements$"Commute.Time" <- unlist(with(acm_df_with_placements, mapply(PickTime, id, placement)))
  # return(sum(acm_df_with_placements$"Commute.Time"))
  # 
  # Old commute calc method (10x slower!)
  #   acm_row <- subset(acm_df_with_placements, id == x)[ , grepl("Time.to.", names(acm_row))]
  #   acm_commute <- acm_row[ , grepl("Time.to.", names(acm_row))]
  #   Actual.Commute.Time <- acm_commute[acm_row$Team.Placement]
  #   acm_commutes <- rbind(acm_commutes, Actual.Commute.Time[1,1])

}

```

```{r}
current_temperature = function(iter, s_curve_amplitude, s_curve_center, s_curve_width) {
  s_curve_amplitude * s_curve(iter, s_curve_center, s_curve_width)
}

s_curve = function(x, center, width) {
  1 / (1 + exp((x - center) / width))
}

```

```{r}
run_intermediate_annealing_process = function(acm_df, team_placements_df, placement_score, best_placements, best_score, starting_iteration, number_of_iterations, s_curve_amplitude, s_curve_center, s_curve_width) {
  
  for(i in 1:number_of_iterations) {
    iter = starting_iteration + i
    temp = current_temperature(iter, s_curve_amplitude, s_curve_center, s_curve_width)
    
    # Create a copy of team_placements
    candidate_placements_df = team_placements_df
    
    # Choose 2 schools at random
    schools_to_swap = sample(1:nrow(school_df), 2)

    # Choose 1 ACM from each of those schools
    swap1 = with(candidate_placements_df, sample(id[candidate_placements_df$id == schools_to_swap[1]], 1))
    swap2 = with(candidate_placements_df, sample(id[candidate_placements_df$id == schools_to_swap[2]], 1))

    # Swap the team assignment of those 2 ACMs
    candidate_placements_df$placement = replace(candidate_placements_df$placement, c(swap1, swap2), candidate_placements_df$placement[c(swap2, swap1)])
    
    # Merge in ACM data
    candidate_score = calculate_score(acm_df, candidate_placements_df)
    
    if (temp > 0) {
      ratio = exp((placement_score - candidate_score) / temp)
    } else {
      ratio = as.numeric(candidate_score < placement_score)
    }
    
    if (runif(1) < ratio) {
      team_placements_df = candidate_placements_df
      placement_score = candidate_score
      
      if (placement_score < best_score) {
        best_placements = team_placements_df
        best_score = placement_score
      }
    }
  }
  
  return(list(team_placements_df=team_placements_df, placement_score=placement_score, best_placements=best_placements, best_score=best_score))
}

```

```{r}
## USEFULL: system.time({ <<code to time>> })

# system.time({ 
output <- run_intermediate_annealing_process(acm_df, team_placements_df, placement_score = 445109, best_placements = team_placements_df, best_score = 445109, starting_iteration = 1, number_of_iterations = 1000, s_curve_amplitude = 4000, s_curve_center = 0, s_curve_width = 3000)
#})
output

```

```{r}
# Convert the team_placement list into a dataframe with an 'id' column 
best_placements_df <- data.frame(id = 1:length(output$best_placements), Team.Placement = output$best_placements)
  
# Merge team_placements_df with acm_df on the 'id' column we just created
acm_df_output <- merge(acm_df, best_placements_df, by = "id", all.x = TRUE)
  
# Merge acm_df_with_placements with school_df to pull in school characteristics
acm_df_output <- merge(acm_df_output, school_df, by.x = "Team.Placement", by.y = "id", all.x = TRUE)

acm_df_output
```

# End Here

# Build Requirements ()

```{r generate logic for invalid assignments}
# E.g., can't allow staff with age < 21 into an HS

IsValid <- function(assign){
  valid <- ifelse(any(assign < 9), FALSE, TRUE) 
  return(valid)
}

```



```{r randomly generate initial assignment}

random.gen <- function(acm_df, school_df){
  nSch <- nrow(school_df)
  nACM <- nrow(acm_df)
  team.size <- ceiling(nACM/nSch)
  assign <- rep(school_df$id, each = team.size) # Creates a vector of 1 10 times, 2 10 times, etc
  random <- sample(x = assign, size = nStu)
    # table(random) # ... This displays a tabulation of the assigned schools
  return(random)
}

repeat{
  myAssign <- random.gen(acm_df, school_df)
  table(myAssign)
  if (IsValid(myAssign)) break
}
```

```{r Gernate Proposal Function}
GenProp <- function(myAssign){
  # picks random to and from schools, and swaps those assignments
  # returns the full assignment
}
```


```{r create objective function}
Obj <- function(myAssign){
  # Takes the assignment, and calcules an objective score combining:
  # 1. minimize commute time
  # 2. college experience or age >= 21 for HS (might also be requirement for valid proposal)
  # 3. bonus for demographic balance (e.g. gender, race/eth, ed)
  # 4. grade-level and perhaps even school preferences
  
  
}
```

```{r create a temperature schedule as a function of step number}

```

```{r implement SA algorithm}

```


* picking initial 'direction'
  * how to set up function to know that there are teams of 9 (or 8, 7, 10, etc)
  * output: series (1, 1, 1, 1, 2, 2, 2, 2, 3, 3, etc.)
* Identify right solution algorithm for our setup
  * GenSA
  * gaoptim -- is for permutation-based problems
  * roll our own (Nick has code for this)

