fake_df$Race.Ethnicity.White.Caucasian[!is.na(fake_df$Race.Ethnicity.African.American.Black)] = sample( c('White/Caucasian', NA), length(fake_df$Race.Ethnicity.White.Caucasian[!is.na(fake_df$Race.Ethnicity.African.American.Black)]), replace=TRUE, prob=c(0.05, 0.95) )
fake_df$Race.Ethnicity.Hispanic.Latino[!is.na(fake_df$Race.Ethnicity.African.American.Black)] = sample( c('Hispanic/Latino', NA), length(fake_df$Race.Ethnicity.Hispanic.Latino[!is.na(fake_df$Race.Ethnicity.African.American.Black)]), replace=TRUE, prob=c(0.1, 0.9) )
fake_df$Race.Ethnicity.Asian[is.na(fake_df$Race.Ethnicity.White.Caucasian) & is.na(fake_df$Race.Ethnicity.African.American.Black)] = sample( c('Asian', NA), length(fake_df$Race.Ethnicity.Asian[is.na(fake_df$Race.Ethnicity.White.Caucasian) & is.na(fake_df$Race.Ethnicity.African.American.Black)]), replace=TRUE, prob=c(0.3, 0.7) )
fake_df$Race.Ethnicity.Hispanic.Latino[is.na(fake_df$Race.Ethnicity.White.Caucasian) & is.na(fake_df$Race.Ethnicity.African.American.Black) & is.na(fake_df$Race.Ethnicity.Asian)] = sample( c('Hispanic/Latino', NA), length(fake_df$Race.Ethnicity.Hispanic.Latino[is.na(fake_df$Race.Ethnicity.White.Caucasian) & is.na(fake_df$Race.Ethnicity.African.American.Black) & is.na(fake_df$Race.Ethnicity.Asian)]), replace=TRUE, prob=c(0.6, 0.4) )
fake_df$Race.Ethnicity.Middle.Eastern[is.na(fake_df$Race.Ethnicity.White.Caucasian) & is.na(fake_df$Race.Ethnicity.African.American.Black) & is.na(fake_df$Race.Ethnicity.Asian) & is.na(fake_df$Race.Ethnicity.Hispanic.Latino)] = sample( c('Middle Eastern', NA), length(fake_df$Race.Ethnicity.Middle.Eastern[is.na(fake_df$Race.Ethnicity.White.Caucasian) & is.na(fake_df$Race.Ethnicity.African.American.Black) & is.na(fake_df$Race.Ethnicity.Asian) & is.na(fake_df$Race.Ethnicity.Hispanic.Latino)]), replace=TRUE, prob=c(0.1, 0.9) )
#fake_df$Race.Ethnicity.Native.Hawaiian.Pacific.Islander = sample( c('Native Hawaiian or Pacific Islander', NA), num_rows, replace=TRUE, prob=c(0.1, 0.9) )
fake_df$Race.Other[is.na(fake_df$Race.Ethnicity.White.Caucasian) & is.na(fake_df$Race.Ethnicity.African.American.Black) & is.na(fake_df$Race.Ethnicity.Asian) & is.na(fake_df$Race.Ethnicity.Hispanic.Latino)] = sample( c('Other'), length(fake_df$Race.Ethnicity.Other[is.na(fake_df$Race.Ethnicity.White.Caucasian) & is.na(fake_df$Race.Ethnicity.African.American.Black) & is.na(fake_df$Race.Ethnicity.Asian) & is.na(fake_df$Race.Ethnicity.Hispanic.Latino)]), replace=TRUE, prob=c(1) )
# Fix conditional survey items so that a "No" answer will cause dependent items to be NA
fake_df$Language.Ability[fake_df$Language.Other.English == 'No'] <- NA
fake_df$Tutoring.Experience.Months[fake_df$Tutoring.Experience == 'No'] <- NA
fake_df$Tutoring.Experience.Grades[fake_df$Tutoring.Experience == 'No'] <- NA
fake_df$Teaching.Credential[fake_df$Tutoring.Experience == 'No'] <- NA
fake_df$Roommate.Names[fake_df$Roomates == 'No'] <- NA
return(fake_df)
}
acm_df_fake <- generate_fake_df(247, school_df, seed=42)
acm_df_fake
#write.table(acm_df_fake, file = "Input 1 - ACM Data.csv", sep=",", row.names=FALSE)
# This function used for Birthdates
fake_dates <- function(N, st="1991/01/01", et="1996/12/31") {
st <- as.POSIXct(as.Date(st))
et <- as.POSIXct(as.Date(et))
dt <- as.numeric(difftime(et,st,unit="secs"))
ev <- runif(N, 0, dt)
rt <- st + ev
trunc(rt, units = "days")}
generate_fake_df <- function(num_rows, school_df, seed = 42){
set.seed(seed)
fake_df <- data.frame(
First.Name = rep('', num_rows),
Last.Name = rep('', num_rows),
Attnd.CY.School = sample( c('I did not attend a City Year school', school_df$`School Name`), num_rows, replace=TRUE, prob=c(0.95, rep(0.01, length(school_df$`School Name`)))),
Language.Other.English =  sample( c('Yes', 'No'), num_rows, replace=TRUE, prob=c(0.2, 0.8) ),
Language.Ability = sample( c('Spanish',
'French',
'Arabic',
'Urdu',
'Nepali',
'Swahili',
'Chinese (Mandarin)',
'Chinese (Cantonese)',
'Polish',
'Other'),
num_rows, replace=TRUE, prob=c(0.25, 0.05, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02,  0.02, 0.02) ),
Tutoring.Experience = sample( c('Yes', 'No'), num_rows, replace=TRUE, prob=c(0.7, 0.3) ),
Tutoring.Experience.Months = sample(1:12, num_rows, replace = TRUE, prob = 12:1),
Tutoring.Experience.Grades = sample( c('Elementary School',
'Elementary School, Middle School',
'Middle School',
'Middle School, High School',
'High School',
'Elementary School, High School',
'Elementary School, Middle School, High School'),
num_rows, replace=TRUE, prob=c(0.15, 0.15, 0.15, 0.15, 0.15, 0.05, 0.1) ),
Teaching.Credential = sample( c('Yes', 'No'), num_rows, replace=TRUE, prob=c(0.1, 0.9) ),
Tutoring.Preference = sample( c('ELA',
'Math',
'Either/No Preference'), num_rows, replace=TRUE, prob=c(0.4, 0.4, 0.2) ),
Grade.Lvl.Preference = sample( c('Elementary School',
'Elementary School, Middle School',
'Middle School',
'Middle School, High School',
'High School',
'Elementary School, High School',
'Elementary School, Middle School, High School'), num_rows, replace=TRUE, prob=c(0.16, 0.16, 0.16, 0.16, 0.16, 0.01, 0.2) ),
Math.Confidence = sample( c('Pre-algebra or lower',
'Algebra I',
'Algebra II',
'Calculus or higher'), num_rows, replace=TRUE, prob=c(0.25, 0.25, 0.25, 0.25) ),
Travel.Method = sample( c('Driving',
'Public Transportation',
'Bicycling',
'Walking'), num_rows, replace=TRUE, prob=c(0.3, 0.6, 0.07, 0.03) ),
Gender = sample( c('Female',
'Male',
'Transgender Male',
'Transgender Female',
'Gender Nonconforming (GNC)'), num_rows, replace=TRUE, prob=c(0.5, 0.3, 0.05, 0.05, 0.1) ),
Birth.Date = fake_dates(num_rows),
Race.Ethnicity.African.American.Black = sample( c('African American/Black', NA), num_rows, replace=TRUE, prob=c(0.4, 0.6) ),
Race.Ethnicity.White.Caucasian = sample( c(NA), num_rows, replace=TRUE, prob=c(1) ),
Race.Ethnicity.Asian =  sample( c(NA), num_rows, replace=TRUE, prob=c(1) ),
Race.Ethnicity.Hispanic.Latino = sample( c(NA), num_rows, replace=TRUE, prob=c(1) ),
Race.Ethnicity.Middle.Eastern = sample( c(NA), num_rows, replace=TRUE, prob=c(1) ),
Race.Ethnicity.Native.Hawaiian.Pacific.Islander =  sample( c(NA), num_rows, replace=TRUE, prob=c(1) ),
Race.Ethnicity.American.Indian.Alaskan.Native = sample( c(NA), num_rows, replace=TRUE, prob=c(1) ),
Race.Ethnicity.Other =  sample( c(NA), num_rows, replace=TRUE, prob=c(1) ),
Educational.Attainment = sample( c('High School/GED',
'Some College',
"Associate's Degree",
"Bachelor's Degree",
"Master's Desgree"),
num_rows,   replace=TRUE, prob=c(0.2, 0.2, 0.15, 0.4, 0.05) ),
Know.Living =  sample( c('Yes', 'No'), num_rows, replace=TRUE, prob=c(0.5, 0.5) ),
Address.Line.1 = rep('', num_rows),
Address.Line.2 = rep('', num_rows),
City = rep('', num_rows),
State =  rep('', num_rows),
Postal.Code = rep('', num_rows),
Roomates = sample( c('Yes', 'No'), num_rows, replace=TRUE, prob=c(0.5, 0.5) ),
Roommate.Names = rep('none', num_rows),
Manual.Placement = sample( c(NA, school_df$`School Name`), num_rows, replace=TRUE, prob=c(0.9, rep(0.01, length(school_df$`School Name`))))
)
# Set at least one race per ACM
fake_df$Race.Ethnicity.White.Caucasian[is.na(fake_df$Race.Ethnicity.African.American.Black)] = sample( c('White/Caucasian', NA), length(fake_df$Race.Ethnicity.White.Caucasian[is.na(fake_df$Race.Ethnicity.African.American.Black)]), replace=TRUE, prob=c(0.8, 0.2) )
fake_df$Race.Ethnicity.White.Caucasian[!is.na(fake_df$Race.Ethnicity.African.American.Black)] = sample( c('White/Caucasian', NA), length(fake_df$Race.Ethnicity.White.Caucasian[!is.na(fake_df$Race.Ethnicity.African.American.Black)]), replace=TRUE, prob=c(0.05, 0.95) )
fake_df$Race.Ethnicity.Hispanic.Latino[!is.na(fake_df$Race.Ethnicity.African.American.Black)] = sample( c('Hispanic/Latino', NA), length(fake_df$Race.Ethnicity.Hispanic.Latino[!is.na(fake_df$Race.Ethnicity.African.American.Black)]), replace=TRUE, prob=c(0.1, 0.9) )
fake_df$Race.Ethnicity.Asian[is.na(fake_df$Race.Ethnicity.White.Caucasian) & is.na(fake_df$Race.Ethnicity.African.American.Black)] = sample( c('Asian', NA), length(fake_df$Race.Ethnicity.Asian[is.na(fake_df$Race.Ethnicity.White.Caucasian) & is.na(fake_df$Race.Ethnicity.African.American.Black)]), replace=TRUE, prob=c(0.3, 0.7) )
fake_df$Race.Ethnicity.Hispanic.Latino[is.na(fake_df$Race.Ethnicity.White.Caucasian) & is.na(fake_df$Race.Ethnicity.African.American.Black) & is.na(fake_df$Race.Ethnicity.Asian)] = sample( c('Hispanic/Latino', NA), length(fake_df$Race.Ethnicity.Hispanic.Latino[is.na(fake_df$Race.Ethnicity.White.Caucasian) & is.na(fake_df$Race.Ethnicity.African.American.Black) & is.na(fake_df$Race.Ethnicity.Asian)]), replace=TRUE, prob=c(0.6, 0.4) )
fake_df$Race.Ethnicity.Middle.Eastern[is.na(fake_df$Race.Ethnicity.White.Caucasian) & is.na(fake_df$Race.Ethnicity.African.American.Black) & is.na(fake_df$Race.Ethnicity.Asian) & is.na(fake_df$Race.Ethnicity.Hispanic.Latino)] = sample( c('Middle Eastern', NA), length(fake_df$Race.Ethnicity.Middle.Eastern[is.na(fake_df$Race.Ethnicity.White.Caucasian) & is.na(fake_df$Race.Ethnicity.African.American.Black) & is.na(fake_df$Race.Ethnicity.Asian) & is.na(fake_df$Race.Ethnicity.Hispanic.Latino)]), replace=TRUE, prob=c(0.1, 0.9) )
#fake_df$Race.Ethnicity.Native.Hawaiian.Pacific.Islander = sample( c('Native Hawaiian or Pacific Islander', NA), num_rows, replace=TRUE, prob=c(0.1, 0.9) )
#fake_df$Race.Ethnicity.American.Indian.Alaskan.Native = sample( c(NA), num_rows, replace=TRUE, prob=c(1) ),
fake_df$Race.Other[is.na(fake_df$Race.Ethnicity.White.Caucasian) & is.na(fake_df$Race.Ethnicity.African.American.Black) & is.na(fake_df$Race.Ethnicity.Asian) & is.na(fake_df$Race.Ethnicity.Hispanic.Latino)] = sample( c('Other'), length(fake_df$Race.Ethnicity.Other[is.na(fake_df$Race.Ethnicity.White.Caucasian) & is.na(fake_df$Race.Ethnicity.African.American.Black) & is.na(fake_df$Race.Ethnicity.Asian) & is.na(fake_df$Race.Ethnicity.Hispanic.Latino)]), replace=TRUE, prob=c(1) )
# Fix conditional survey items so that a "No" answer will cause dependent items to be NA
fake_df$Language.Ability[fake_df$Language.Other.English == 'No'] <- NA
fake_df$Tutoring.Experience.Months[fake_df$Tutoring.Experience == 'No'] <- NA
fake_df$Tutoring.Experience.Grades[fake_df$Tutoring.Experience == 'No'] <- NA
fake_df$Teaching.Credential[fake_df$Tutoring.Experience == 'No'] <- NA
fake_df$Roommate.Names[fake_df$Roomates == 'No'] <- NA
return(fake_df)
}
acm_df_fake <- generate_fake_df(247, school_df, seed=42)
acm_df_fake
#write.table(acm_df_fake, file = "Input 1 - ACM Data.csv", sep=",", row.names=FALSE)
# This function used for Birthdates
fake_dates <- function(N, st="1991/01/01", et="1996/12/31") {
st <- as.POSIXct(as.Date(st))
et <- as.POSIXct(as.Date(et))
dt <- as.numeric(difftime(et,st,unit="secs"))
ev <- runif(N, 0, dt)
rt <- st + ev
trunc(rt, units = "days")}
generate_fake_df <- function(num_rows, school_df, seed = 42){
set.seed(seed)
fake_df <- data.frame(
First.Name = rep('', num_rows),
Last.Name = rep('', num_rows),
Attnd.CY.School = sample( c('I did not attend a City Year school', school_df$`School Name`), num_rows, replace=TRUE, prob=c(0.95, rep(0.01, length(school_df$`School Name`)))),
Language.Other.English =  sample( c('Yes', 'No'), num_rows, replace=TRUE, prob=c(0.2, 0.8) ),
Language.Ability = sample( c('Spanish',
'French',
'Arabic',
'Urdu',
'Nepali',
'Swahili',
'Chinese (Mandarin)',
'Chinese (Cantonese)',
'Polish',
'Other'),
num_rows, replace=TRUE, prob=c(0.25, 0.05, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02,  0.02, 0.02) ),
Tutoring.Experience = sample( c('Yes', 'No'), num_rows, replace=TRUE, prob=c(0.7, 0.3) ),
Tutoring.Experience.Months = sample(1:12, num_rows, replace = TRUE, prob = 12:1),
Tutoring.Experience.Grades = sample( c('Elementary School',
'Elementary School, Middle School',
'Middle School',
'Middle School, High School',
'High School',
'Elementary School, High School',
'Elementary School, Middle School, High School'),
num_rows, replace=TRUE, prob=c(0.15, 0.15, 0.15, 0.15, 0.15, 0.05, 0.1) ),
Teaching.Credential = sample( c('Yes', 'No'), num_rows, replace=TRUE, prob=c(0.1, 0.9) ),
Tutoring.Preference = sample( c('ELA',
'Math',
'Either/No Preference'), num_rows, replace=TRUE, prob=c(0.4, 0.4, 0.2) ),
Grade.Lvl.Preference = sample( c('Elementary School',
'Elementary School, Middle School',
'Middle School',
'Middle School, High School',
'High School',
'Elementary School, High School',
'Elementary School, Middle School, High School'), num_rows, replace=TRUE, prob=c(0.16, 0.16, 0.16, 0.16, 0.16, 0.01, 0.2) ),
Math.Confidence = sample( c('Pre-algebra or lower',
'Algebra I',
'Algebra II',
'Calculus or higher'), num_rows, replace=TRUE, prob=c(0.25, 0.25, 0.25, 0.25) ),
Travel.Method = sample( c('Driving',
'Public Transportation',
'Bicycling',
'Walking'), num_rows, replace=TRUE, prob=c(0.3, 0.6, 0.07, 0.03) ),
Gender = sample( c('Female',
'Male',
'Transgender Male',
'Transgender Female',
'Gender Nonconforming (GNC)'), num_rows, replace=TRUE, prob=c(0.5, 0.3, 0.05, 0.05, 0.1) ),
Birth.Date = fake_dates(num_rows),
Race.Ethnicity.African.American.Black = sample( c('African American/Black', NA), num_rows, replace=TRUE, prob=c(0.4, 0.6) ),
Race.Ethnicity.White.Caucasian = sample( c(NA), num_rows, replace=TRUE, prob=c(1) ),
Race.Ethnicity.Asian =  sample( c(NA), num_rows, replace=TRUE, prob=c(1) ),
Race.Ethnicity.Hispanic.Latino = sample( c(NA), num_rows, replace=TRUE, prob=c(1) ),
Race.Ethnicity.Middle.Eastern = sample( c(NA), num_rows, replace=TRUE, prob=c(1) ),
#Race.Ethnicity.Native.Hawaiian.Pacific.Islander =  sample( c(NA), num_rows, replace=TRUE, prob=c(1) ),
#Race.Ethnicity.American.Indian.Alaskan.Native = sample( c(NA), num_rows, replace=TRUE, prob=c(1) ),
Race.Ethnicity.Other =  sample( c(NA), num_rows, replace=TRUE, prob=c(1) ),
Educational.Attainment = sample( c('High School/GED',
'Some College',
"Associate's Degree",
"Bachelor's Degree",
"Master's Desgree"),
num_rows,   replace=TRUE, prob=c(0.2, 0.2, 0.15, 0.4, 0.05) ),
Know.Living =  sample( c('Yes', 'No'), num_rows, replace=TRUE, prob=c(0.5, 0.5) ),
Address.Line.1 = rep('', num_rows),
Address.Line.2 = rep('', num_rows),
City = rep('', num_rows),
State =  rep('', num_rows),
Postal.Code = rep('', num_rows),
Roomates = sample( c('Yes', 'No'), num_rows, replace=TRUE, prob=c(0.5, 0.5) ),
Roommate.Names = rep('none', num_rows),
Manual.Placement = sample( c(NA, school_df$`School Name`), num_rows, replace=TRUE, prob=c(0.9, rep(0.01, length(school_df$`School Name`))))
)
# Set at least one race per ACM
fake_df$Race.Ethnicity.White.Caucasian[is.na(fake_df$Race.Ethnicity.African.American.Black)] = sample( c('White/Caucasian', NA), length(fake_df$Race.Ethnicity.White.Caucasian[is.na(fake_df$Race.Ethnicity.African.American.Black)]), replace=TRUE, prob=c(0.8, 0.2) )
fake_df$Race.Ethnicity.White.Caucasian[!is.na(fake_df$Race.Ethnicity.African.American.Black)] = sample( c('White/Caucasian', NA), length(fake_df$Race.Ethnicity.White.Caucasian[!is.na(fake_df$Race.Ethnicity.African.American.Black)]), replace=TRUE, prob=c(0.05, 0.95) )
fake_df$Race.Ethnicity.Hispanic.Latino[!is.na(fake_df$Race.Ethnicity.African.American.Black)] = sample( c('Hispanic/Latino', NA), length(fake_df$Race.Ethnicity.Hispanic.Latino[!is.na(fake_df$Race.Ethnicity.African.American.Black)]), replace=TRUE, prob=c(0.1, 0.9) )
fake_df$Race.Ethnicity.Asian[is.na(fake_df$Race.Ethnicity.White.Caucasian) & is.na(fake_df$Race.Ethnicity.African.American.Black)] = sample( c('Asian', NA), length(fake_df$Race.Ethnicity.Asian[is.na(fake_df$Race.Ethnicity.White.Caucasian) & is.na(fake_df$Race.Ethnicity.African.American.Black)]), replace=TRUE, prob=c(0.3, 0.7) )
fake_df$Race.Ethnicity.Hispanic.Latino[is.na(fake_df$Race.Ethnicity.White.Caucasian) & is.na(fake_df$Race.Ethnicity.African.American.Black) & is.na(fake_df$Race.Ethnicity.Asian)] = sample( c('Hispanic/Latino', NA), length(fake_df$Race.Ethnicity.Hispanic.Latino[is.na(fake_df$Race.Ethnicity.White.Caucasian) & is.na(fake_df$Race.Ethnicity.African.American.Black) & is.na(fake_df$Race.Ethnicity.Asian)]), replace=TRUE, prob=c(0.6, 0.4) )
fake_df$Race.Ethnicity.Middle.Eastern[is.na(fake_df$Race.Ethnicity.White.Caucasian) & is.na(fake_df$Race.Ethnicity.African.American.Black) & is.na(fake_df$Race.Ethnicity.Asian) & is.na(fake_df$Race.Ethnicity.Hispanic.Latino)] = sample( c('Middle Eastern', NA), length(fake_df$Race.Ethnicity.Middle.Eastern[is.na(fake_df$Race.Ethnicity.White.Caucasian) & is.na(fake_df$Race.Ethnicity.African.American.Black) & is.na(fake_df$Race.Ethnicity.Asian) & is.na(fake_df$Race.Ethnicity.Hispanic.Latino)]), replace=TRUE, prob=c(0.1, 0.9) )
#fake_df$Race.Ethnicity.Native.Hawaiian.Pacific.Islander = sample( c('Native Hawaiian or Pacific Islander', NA), num_rows, replace=TRUE, prob=c(0.1, 0.9) )
#fake_df$Race.Ethnicity.American.Indian.Alaskan.Native = sample( c(NA), num_rows, replace=TRUE, prob=c(1) ),
fake_df$Race.Other[is.na(fake_df$Race.Ethnicity.White.Caucasian) & is.na(fake_df$Race.Ethnicity.African.American.Black) & is.na(fake_df$Race.Ethnicity.Asian) & is.na(fake_df$Race.Ethnicity.Hispanic.Latino)] = sample( c('Other'), length(fake_df$Race.Ethnicity.Other[is.na(fake_df$Race.Ethnicity.White.Caucasian) & is.na(fake_df$Race.Ethnicity.African.American.Black) & is.na(fake_df$Race.Ethnicity.Asian) & is.na(fake_df$Race.Ethnicity.Hispanic.Latino)]), replace=TRUE, prob=c(1) )
# Fix conditional survey items so that a "No" answer will cause dependent items to be NA
fake_df$Language.Ability[fake_df$Language.Other.English == 'No'] <- NA
fake_df$Tutoring.Experience.Months[fake_df$Tutoring.Experience == 'No'] <- NA
fake_df$Tutoring.Experience.Grades[fake_df$Tutoring.Experience == 'No'] <- NA
fake_df$Teaching.Credential[fake_df$Tutoring.Experience == 'No'] <- NA
fake_df$Roommate.Names[fake_df$Roomates == 'No'] <- NA
return(fake_df)
}
acm_df_fake <- generate_fake_df(247, school_df, seed=42)
write.table(acm_df_fake, file = "Input 1 - ACM Data.csv", sep=",", row.names=FALSE)
acm_df <- read.csv(file = "Input 1 - ACM Data.csv")
acm_commutes <- read_excel(path = "Input 2 - ACM Commutes.xlsx")
school_df <- read_excel(path = "Input 3 - School Data.xls")
# Add id columns
acm_df$acm_id <- 1:nrow(acm_df)
acm_commutes$acm_id <- 1:nrow(acm_commutes)
school_df$sch_id <- 1:nrow(school_df)
# Commute times in long format will be easier to index and subset. This can be accomplished in the output of "gmapsdistance" function later.
acm_commutes_long <-
select(acm_commutes, -or) %>%
gather(dest, dist, -acm_id) %>%
mutate(id_dest = paste(acm_id, dest, sep = "_"))
library(gmapsdistance)
library(readxl)
#library("googleway")
library(dplyr)
library(tidyr)
library(data.table)
library(dummies)
acm_df <- read.csv(file = "Input 1 - ACM Data.csv")
acm_commutes <- read_excel(path = "Input 2 - ACM Commutes.xlsx")
school_df <- read_excel(path = "Input 3 - School Data.xls")
# Add id columns
acm_df$acm_id <- 1:nrow(acm_df)
acm_commutes$acm_id <- 1:nrow(acm_commutes)
school_df$sch_id <- 1:nrow(school_df)
# Commute times in long format will be easier to index and subset. This can be accomplished in the output of "gmapsdistance" function later.
acm_commutes_long <-
select(acm_commutes, -or) %>%
gather(dest, dist, -acm_id) %>%
mutate(id_dest = paste(acm_id, dest, sep = "_"))
var(c(100))
var(c(100, 2))
var(c(98, 2))
var(c(50, 50, 50, 50))
var(c(15, 15, 15, 15, 20, 20))
var(c(4/9, 4/9, 4/9, 4/9, 4/9, 4/9, 4/9, 4/9, 1/9))
var(c(4/10, 4/10, 4/10, 4/10, 5/10, 5/10, 5/10, 5/10, 5/10, 1/10))
var(c(4/9, 4/9, 4/9, 4/9, 4/9, 4/9, 4/9, 4/9, 1/9))
var(c(4/10, 4/10, 4/10, 4/10, 5/10, 5/10, 5/10, 5/10, 5/10, 1/10))
var(c(4/9, 4/9, 4/9, 4/9, 4/9, 4/9, 4/9, 4/9, 1/9))
var(c(4/10, 4/10, 4/10, 4/10, 5/10, 5/10, 5/10, 5/10, 5/10, 1/10))
var(c(8/18, 8/18, 8/18, 8/18, 9/18, 9/18, 9/18, 9/18, 9/18, 1/18))
((4/10) * 4 + (5/10) * 5 + 1/10)/10
(8/9 * 8 + 1/9) / 9
library(gmapsdistance)
library(readxl)
#library("googleway")
library(dplyr)
library(tidyr)
library(data.table)
library(dummies)
acm_df <- read.csv(file = "Input 1 - ACM Data.csv")
acm_commutes <- read_excel(path = "Input 2 - ACM Commutes.xlsx")
school_df <- read_excel(path = "Input 3 - School Data.xls")
# Add id columns
acm_df$acm_id <- 1:nrow(acm_df)
acm_commutes$acm_id <- 1:nrow(acm_commutes)
school_df$sch_id <- 1:nrow(school_df)
# Commute times in long format will be easier to index and subset. This can be accomplished in the output of "gmapsdistance" function later.
acm_commutes_long <-
select(acm_commutes, -or) %>%
gather(dest, dist, -acm_id) %>%
mutate(id_dest = paste(acm_id, dest, sep = "_"))
# This function takes the input acm_df and encodes the variables in a way that makes the mathematically tractable.
encode_acm_df <- function(df){
acm_enc <- select(df, acm_id)
# Ed Attainment
acm_enc$Ed_HS <- as.numeric(grepl("High School/GED", df$Educational.Attainment))
acm_enc$Ed_SomeCol <- grepl("Some College", df$Educational.Attainment) + grepl("Associate's Degree", df$Educational.Attainment)
acm_enc$Ed_Col <- grepl("Bachelor's Degree", df$Educational.Attainment) + grepl("Master's Degree", df$Educational.Attainment)
# Tutoring Experience
acm_enc$HasTutored <- ifelse(df$Tutoring.Experience == "Yes", 1, 0)
# Tutoring Preference
acm_enc$Pref_HS <- as.numeric(grepl("High School", df$Grade.Lvl.Preference))
acm_enc$Pref_MS <- as.numeric(grepl("Middle School", df$Grade.Lvl.Preference))
acm_enc$Pref_ES <- as.numeric(grepl("Elementary School", df$Grade.Lvl.Preference))
# Math Proficiency
acm_enc$Math_Confidence <- ifelse(df$Math.Confidence == "Pre-Algebra or lower" | df$Math.Confidence == "Algebra I", 0, 1)
# Language Ability
acm_enc$SpanishAble <- ifelse(df$Language.Ability == "Spanish", 1, 0)
acm_enc$SpanishAble[is.na(acm_enc$SpanishAble)] <- 0
acm_enc$Lang_Other <- ifelse((df$Language.Other.English == "Yes") & (df$Language.Ability != "Spanish"), 1, 0)
# Add in other features
acm_enc <- acm_enc %>%
left_join(., select(acm_df,
acm_id,
Gender,
Manual.Placement,
Birth.Date,
Race.Ethnicity.African.American.Black:Race.Ethnicity.Other), by=c("acm_id" = "acm_id"))
# Return
acm_enc
}
# School configuration data frame. I think we could probably reduce the school configuration file to just the following elements: school name, team size, address, and local ethnic demographics.  From those data points alone and the corps demographic data, we should be able to calculate everything else.
# This function calculates some import counts which I'm going to use a lot when trying to figure out the expected number of ACMs per team per metric.  This function will just be used internally by the school_config function.
corps_demographic_targets <- function(school_df, acm_enc){
# Calculate some totals used later in the function
N <- nrow(acm_enc)
S <- nrow(school_df)
# Counts of schools by level
school_counts <- group_by(school_df, `School Type`) %>% summarise(count=n())
# Approximation of densly spanish speaking schools
dense_hispanic <- nrow(school_df[school_df$`% Hispanic` > 10, ])
# We'll store our results in a list so we can return multiple tables
distros <- list()
# Produce ratio of folks who have completed at least an associates, and those who haven't
distros$education <- data.frame(level = c("HS", "SomeCol"), ratio = c(nrow(acm_enc[acm_enc$Ed_HS == 1,]) / N, nrow(acm_enc[acm_enc$Ed_SomeCol == 1,]) / N))
# Identify rates of Tutoring Experience
distros$tut_exp <- group_by(acm_enc, HasTutored) %>%
summarise(count=n()) %>%
mutate(ratio = count/N)
# Spanish and other spoken language distribution
distros$lang <- data.frame(ability = c("other"), ratio = c(nrow(acm_enc[acm_enc$Lang_Other == 1, ]) / N))
# Math Ability
distros$math <- nrow(acm_enc[acm_enc$Math_Confidence == 1,]) / N
# Note on tutoring pref.  We'll simply set this parameter to the team size appropriate for the level type.  This should thus maximize the incentive on putting folks with the appropriate tutoring pref at the appropriate levels.
distros
}
# I derived this function mildly arbitrarily. The logic is that we probably want at least one spanish speaker at a school, but there are then diminishing returns.  It scales so that for a school that 100% hispanic, we would aim to have 5 spanish speakers on the team.  A team thats 50% hispanic will aim to have 4. The main problem with this approach is that we may create too many spots for spanish speakers, or have not have enough spanish speakers for the intended spots.
spanishNeed <- function(x) {
1.5772*log(x) - 2.1205
}
# Directly calculates the expected number of ACMs per team for each of the markers.
# My methodology is to aim for a uniform distribution when it makes sense.
school_config <- function(school_df, acm_enc){
# Precalculate some helpful counts
corps_demos <- corps_demographic_targets(school_df, acm_enc)
# Unravel list into some variables.  Mostly so that the code is a little cleaner later.
education <- corps_demos$education
lang <- corps_demos$lang
tut_exp <- corps_demos$tut_exp
math <- corps_demos$math
school.data <- select(school_df, `sch_id`, `Team Size`, `School Type`, `% Caucasian`:`% N/A`) %>%
rename(size = `Team Size`,
span = `School Type`) %>%
mutate(HSGrad_tgt = ifelse(span=="HS", 0, education[education$level %in% 'HS',]$ratio * size),
SomeCol_tgt = education[education$level %in% 'SomeCol',]$ratio * size,
SpanPref_ES = ifelse(span=="ES", size, 0),
SpanPref_MS = ifelse(span=="MS", size, 0),
SpanPref_HS = ifelse(span=="HS", size, 0),
TutExp = size * tut_exp[tut_exp$HasTutored == 1,]$ratio,
SpanishNeed = pmax(spanishNeed(`% Hispanic`), 1),# This sets a minimum of 1 spanish speaker per team.  This might make sense in LA, but not other places.
OtherLang_tgt = lang[lang$ability %in% 'other',]$ratio * size,
Math_tgt = ifelse(span=="ES", size*.5*math, ifelse(span=="MS", .75*size*math, size*math)))
}
acm_enc <- encode_acm_df(acm_df)
school_targets <- school_config(school_df, acm_enc)
school_targets
# Assumption: the number of ACMs in acm_df is exactly the same as the number of team slots
initial_placement <- function(seed=42, acm_enc, school_targets){
# First place acm's at schools designated by Manual.Placement column
# first create an empty list
team_placements = list()
# use a for-loop to read each team size
for (x in 1:nrow(school_targets)){
team_slots = list(
# create a list that repeats each school 'id' for the size of each team
rep(x,
subset(school_targets$size, school_targets$sch_id == x)
)
)
team_placements <- c(team_placements, team_slots)
}
team_placements <- data.frame(placement=unlist(team_placements))
# Randomize Starting Place
#set.seed(seed)
team_placements_df <- data.frame(placement=team_placements[sample(nrow(team_placements), replace=F), ],
acm_id= 1:nrow(team_placements))
# Merge team_placements_df with acm_df on the 'id' column
team_placements_df <- merge(acm_enc, team_placements_df, by = "acm_id", all.x = TRUE)
# Honor Manual Placements
sch_id_names <- school_df[, c("sch_id", "School Name")]
colnames(sch_id_names) <- c("Manual.Placement_id", "School.Name")
team_placements_df <- merge(team_placements_df, sch_id_names, by.x = "Manual.Placement", by.y = "School.Name", all.x = TRUE)
acms_with_Manual.Placement <- subset(team_placements_df, (!is.na(team_placements_df$Manual.Placement)))
acms_no_Manual.Placement <- subset(team_placements_df, (is.na(team_placements_df$Manual.Placement)))
for (x in acms_with_Manual.Placement$acm_id){
team_placements_df <- team_placements_df[order(team_placements_df$acm_id), ]
rownames(team_placements_df) <- 1:nrow(team_placements_df)
acm_row <- subset(acms_with_Manual.Placement, acms_with_Manual.Placement$acm_id == x)
# Choose 1 acm_id currently assigned to the school at which we want to ensure manual placement is honored
acm_id_to_swap <- sample( subset( acms_no_Manual.Placement$acm_id, acms_no_Manual.Placement$placement == acm_row$Manual.Placement_id ), 1 )
# Swap the team assignment of those 2 ACMs
swap1 <- acm_row$acm_id
swap2 <- acm_id_to_swap
team_placements_df$placement <- replace(team_placements_df$placement, c(swap1, swap2), team_placements_df$placement[c(swap2, swap1)])
}
# We would like to ensure that high school students get placed in ES or MS
acms_for_swaps <- merge(team_placements_df[is.na(team_placements_df$Manual.Placement_id), ], school_targets, by.x = "placement", by.y = "sch_id", all.x = TRUE)
#print(acms_for_swaps)
hs_acms_to_swap <- acms_for_swaps[(acms_for_swaps$Ed_HS == 1) & (acms_for_swaps$span == "HS"),]
acms_to_swap_with <- acms_for_swaps[(acms_for_swaps$Ed_HS == 0) & (acms_for_swaps$span != "HS"),]
acms_to_swap_with <- acms_to_swap_with[sample(nrow(acms_to_swap_with), nrow(hs_acms_to_swap), replace=F), ]
team_placements_df[team_placements_df$acm_id %in% hs_acms_to_swap$acm_id, ]$placement = acms_to_swap_with$placement
team_placements_df[team_placements_df$acm_id %in% acms_to_swap_with$acm_id, ]$placement = hs_acms_to_swap$placement
return(team_placements_df)
}
misplaced_youth <- function(init_placement){
youth <- init_placement %>%
filter(is.na(init_placement$Manual.Placement) == T) %>%
left_join(., school_targets, by= c("placement"="sch_id")) %>%
select(acm_id, placement, Ed_HS, span, HSGrad_tgt, Manual.Placement) %>%
filter(Ed_HS == 1 & HSGrad_tgt == 0)
}
team_placements_df <- initial_placement(seed=42, acm_enc, school_targets)
youth <- misplaced_youth(team_placements_df)
team_placements_df
system.time({
team_placements_df$dest = colnames(acm_commutes)[team_placements_df$placement + 1]
team_placements_df <- within(team_placements_df, id_dest <- paste(acm_id, dest, sep = "_"))
dt_commutes <- data.table(acm_commutes_long)
scores$commute_score <- dt_commutes[id_dest %in% team_placements_df$id_dest,  sum(dist)]
})
commute_score <- dt_commutes[id_dest %in% team_placements_df$id_dest,  sum(dist)]
system.time({
team_placements_df$dest = colnames(acm_commutes)[team_placements_df$placement + 1]
team_placements_df <- within(team_placements_df, id_dest <- paste(acm_id, dest, sep = "_"))
dt_commutes <- data.table(acm_commutes_long)
commute_score <- dt_commutes[id_dest %in% team_placements_df$id_dest,  sum(dist)]
})
system.time({
gender_frame <-
expand.grid(placement = 1:nrow(school_targets), Gender = levels(team_placements_df$Gender))
# Create tibbl containing percentage representation of each gender category across the entire corps
gender_g <- group_by(acm_df, Gender) %>% summarize(pct_g = n()/nrow(team_placements_df))
# Merge previous two frames by "gender"
gender_frame_g <-
merge(x = gender_frame,
y = gender_g,
by = "Gender",
all.x = TRUE)
# Represent percentage of each gender category within each team
gender_gs <-
team_placements_df %>%
group_by(placement, Gender) %>%
dplyr::summarize(n_gs = n()) %>%
group_by(placement) %>%
dplyr::mutate(pct_gs = n_gs/sum(n_gs))
# Calculate absolute value of difference between gender percentages at each team and across the corps
gender_frame_gs <-
merge(x = gender_frame_g,
y = gender_gs,
by = c("placement", "Gender"),
all.x = TRUE) %>%
within({
diff_gs <- pct_g - ifelse(is.na(pct_gs), 0, pct_gs)
abs_diff_gs <- abs(diff_gs)
}) %>%
summarise(mean_gend_diff = mean(abs_diff_gs))
gender_score <- gender_frame_gs$mean_gend_diff * 10000000 / 2
})
system.time({
gender_frame <-
expand.grid(placement = 1:nrow(school_targets), Gender = levels(team_placements_df$Gender))
# Create tibbl containing percentage representation of each gender category across the entire corps
gender_g <- group_by(acm_df, Gender) %>% summarize(pct_g = n()/nrow(team_placements_df))
# Merge previous two frames by "gender"
gender_frame_g <-
merge(x = gender_frame,
y = gender_g,
by = "Gender",
all.x = TRUE)
# Represent percentage of each gender category within each team
gender_gs <-
team_placements_df %>%
group_by(placement, Gender) %>%
dplyr::summarize(n_gs = n()) %>%
group_by(placement) %>%
dplyr::mutate(pct_gs = n_gs/sum(n_gs))
# Calculate absolute value of difference between gender percentages at each team and across the corps
gender_frame_gs <-
merge(x = gender_frame_g,
y = gender_gs,
by = c("placement", "Gender"),
all.x = TRUE) %>%
within({
diff_gs <- pct_g - ifelse(is.na(pct_gs), 0, pct_gs)
abs_diff_gs <- abs(diff_gs)
}) %>%
summarise(mean_gend_diff = mean(abs_diff_gs))
gender_score <- gender_frame_gs$mean_gend_diff * 10000000 / 2
})
